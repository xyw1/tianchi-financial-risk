{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir as ld\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submit.csv', 'testA.csv', 'train.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld('../input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = pd.read_csv('../input/testA.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv').iloc[:1000,]\n",
    "train['subGrade']=list(map(lambda x:int(re.sub('[A-Z]','',x)),train['subGrade']))\n",
    "train['grade']=list(map(lambda x:ord(x)-64,train['grade']))\n",
    "issueDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.remove('issueDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.remove('earliesCreditLine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-a1b48d66e142>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'employmentLength'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "    cols.remove('employmentLength') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loanAmnt</th>\n",
       "      <th>term</th>\n",
       "      <th>interestRate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>subGrade</th>\n",
       "      <th>employmentTitle</th>\n",
       "      <th>homeOwnership</th>\n",
       "      <th>annualIncome</th>\n",
       "      <th>...</th>\n",
       "      <th>n5</th>\n",
       "      <th>n6</th>\n",
       "      <th>n7</th>\n",
       "      <th>n8</th>\n",
       "      <th>n9</th>\n",
       "      <th>n10</th>\n",
       "      <th>n11</th>\n",
       "      <th>n12</th>\n",
       "      <th>n13</th>\n",
       "      <th>n14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>19.52</td>\n",
       "      <td>917.97</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>320.0</td>\n",
       "      <td>2</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>18.49</td>\n",
       "      <td>461.90</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>219843.0</td>\n",
       "      <td>0</td>\n",
       "      <td>46000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>16.99</td>\n",
       "      <td>298.17</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>31698.0</td>\n",
       "      <td>0</td>\n",
       "      <td>74000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.26</td>\n",
       "      <td>340.96</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>46854.0</td>\n",
       "      <td>1</td>\n",
       "      <td>118000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>12.99</td>\n",
       "      <td>101.07</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  loanAmnt  term  interestRate  installment  grade  subGrade  \\\n",
       "0   0   35000.0     5         19.52       917.97      5         2   \n",
       "1   1   18000.0     5         18.49       461.90      4         2   \n",
       "2   2   12000.0     5         16.99       298.17      4         3   \n",
       "3   3   11000.0     3          7.26       340.96      1         4   \n",
       "4   4    3000.0     3         12.99       101.07      3         2   \n",
       "\n",
       "   employmentTitle  homeOwnership  annualIncome  ...    n5    n6    n7    n8  \\\n",
       "0            320.0              2      110000.0  ...   9.0   8.0   4.0  12.0   \n",
       "1         219843.0              0       46000.0  ...   NaN   NaN   NaN   NaN   \n",
       "2          31698.0              0       74000.0  ...   0.0  21.0   4.0   5.0   \n",
       "3          46854.0              1      118000.0  ...  16.0   4.0   7.0  21.0   \n",
       "4             54.0              1       29000.0  ...   4.0   9.0  10.0  15.0   \n",
       "\n",
       "    n9   n10  n11  n12  n13  n14  \n",
       "0  2.0   7.0  0.0  0.0  0.0  2.0  \n",
       "1  NaN  13.0  NaN  NaN  NaN  NaN  \n",
       "2  3.0  11.0  0.0  0.0  0.0  4.0  \n",
       "3  6.0   9.0  0.0  0.0  0.0  1.0  \n",
       "4  7.0  12.0  0.0  0.0  0.0  4.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio=0.9\n",
    "train_size = int(train.shape[0]*split_ratio)\n",
    "train_data_x = (train.iloc[:train_size,1:]).values.astype('float32')\n",
    "train_data_y = (train.iloc[:train_size,0]).values.astype('int32')\n",
    "test_data_x = (train.iloc[train_size:,1:]).values.astype('float32')\n",
    "test_data_y = (train.iloc[train_size:,0]).values.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunwanx/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(train_data_x, train_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_y_pred_logistic = clf.predict(test_data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          18       0.00      0.00      0.00       0.0\n",
      "          35       0.00      0.00      0.00       0.0\n",
      "          41       0.00      0.00      0.00       0.0\n",
      "          54       0.00      0.00      0.00       0.0\n",
      "          61       0.00      0.00      0.00       0.0\n",
      "          65       0.00      0.00      0.00       0.0\n",
      "          76       0.00      0.00      0.00       0.0\n",
      "          88       0.00      0.00      0.00       0.0\n",
      "         121       0.00      0.00      0.00       0.0\n",
      "         122       0.00      0.00      0.00       0.0\n",
      "         126       0.00      0.00      0.00       0.0\n",
      "         128       0.00      0.00      0.00       0.0\n",
      "         153       0.00      0.00      0.00       0.0\n",
      "         200       0.00      0.00      0.00       0.0\n",
      "         227       0.00      0.00      0.00       0.0\n",
      "         250       0.00      0.00      0.00       0.0\n",
      "         253       0.00      0.00      0.00       0.0\n",
      "         261       0.00      0.00      0.00       0.0\n",
      "         269       0.00      0.00      0.00       0.0\n",
      "         293       0.00      0.00      0.00       0.0\n",
      "         310       0.00      0.00      0.00       0.0\n",
      "         324       0.00      0.00      0.00       0.0\n",
      "         326       0.00      0.00      0.00       0.0\n",
      "         336       0.00      0.00      0.00       0.0\n",
      "         342       0.00      0.00      0.00       0.0\n",
      "         379       0.00      0.00      0.00       0.0\n",
      "         403       0.00      0.00      0.00       0.0\n",
      "         414       0.00      0.00      0.00       0.0\n",
      "         429       0.00      0.00      0.00       0.0\n",
      "         432       0.00      0.00      0.00       0.0\n",
      "         440       0.00      0.00      0.00       0.0\n",
      "         462       0.00      0.00      0.00       0.0\n",
      "         465       0.00      0.00      0.00       0.0\n",
      "         502       0.00      0.00      0.00       0.0\n",
      "         505       0.00      0.00      0.00       0.0\n",
      "         536       0.00      0.00      0.00       0.0\n",
      "         544       0.00      0.00      0.00       0.0\n",
      "         548       0.00      0.00      0.00       0.0\n",
      "         559       0.00      0.00      0.00       0.0\n",
      "         563       0.00      0.00      0.00       0.0\n",
      "         574       0.00      0.00      0.00       0.0\n",
      "         578       0.00      0.00      0.00       0.0\n",
      "         587       0.00      0.00      0.00       0.0\n",
      "         588       0.00      0.00      0.00       0.0\n",
      "         594       0.00      0.00      0.00       0.0\n",
      "         602       0.00      0.00      0.00       0.0\n",
      "         614       0.00      0.00      0.00       0.0\n",
      "         619       0.00      0.00      0.00       0.0\n",
      "         636       0.00      0.00      0.00       0.0\n",
      "         645       0.00      0.00      0.00       0.0\n",
      "         654       0.00      0.00      0.00       0.0\n",
      "         657       0.00      0.00      0.00       0.0\n",
      "         660       0.00      0.00      0.00       0.0\n",
      "         676       0.00      0.00      0.00       0.0\n",
      "         686       0.00      0.00      0.00       0.0\n",
      "         693       0.00      0.00      0.00       0.0\n",
      "         716       0.00      0.00      0.00       0.0\n",
      "         717       0.00      0.00      0.00       0.0\n",
      "         737       0.00      0.00      0.00       0.0\n",
      "         777       0.00      0.00      0.00       0.0\n",
      "         791       0.00      0.00      0.00       0.0\n",
      "         798       0.00      0.00      0.00       0.0\n",
      "         803       0.00      0.00      0.00       0.0\n",
      "         816       0.00      0.00      0.00       0.0\n",
      "         840       0.00      0.00      0.00       0.0\n",
      "         843       0.00      0.00      0.00       0.0\n",
      "         848       0.00      0.00      0.00       0.0\n",
      "         865       0.00      0.00      0.00       0.0\n",
      "         871       0.00      0.00      0.00       0.0\n",
      "         900       0.00      0.00      0.00       0.0\n",
      "         904       0.00      0.00      0.00       1.0\n",
      "         905       0.00      0.00      0.00       1.0\n",
      "         906       0.00      0.00      0.00       1.0\n",
      "         907       0.00      0.00      0.00       1.0\n",
      "         908       0.00      0.00      0.00       1.0\n",
      "         909       0.00      0.00      0.00       1.0\n",
      "         911       0.00      0.00      0.00       1.0\n",
      "         912       0.00      0.00      0.00       1.0\n",
      "         913       0.00      0.00      0.00       1.0\n",
      "         914       0.00      0.00      0.00       1.0\n",
      "         915       0.00      0.00      0.00       1.0\n",
      "         916       0.00      0.00      0.00       1.0\n",
      "         917       0.00      0.00      0.00       1.0\n",
      "         918       0.00      0.00      0.00       1.0\n",
      "         919       0.00      0.00      0.00       1.0\n",
      "         920       0.00      0.00      0.00       1.0\n",
      "         921       0.00      0.00      0.00       1.0\n",
      "         922       0.00      0.00      0.00       1.0\n",
      "         923       0.00      0.00      0.00       1.0\n",
      "         924       0.00      0.00      0.00       1.0\n",
      "         925       0.00      0.00      0.00       1.0\n",
      "         926       0.00      0.00      0.00       1.0\n",
      "         927       0.00      0.00      0.00       1.0\n",
      "         928       0.00      0.00      0.00       1.0\n",
      "         929       0.00      0.00      0.00       1.0\n",
      "         930       0.00      0.00      0.00       1.0\n",
      "         931       0.00      0.00      0.00       1.0\n",
      "         932       0.00      0.00      0.00       1.0\n",
      "         933       0.00      0.00      0.00       1.0\n",
      "         934       0.00      0.00      0.00       1.0\n",
      "         935       0.00      0.00      0.00       1.0\n",
      "         936       0.00      0.00      0.00       1.0\n",
      "         937       0.00      0.00      0.00       1.0\n",
      "         938       0.00      0.00      0.00       1.0\n",
      "         939       0.00      0.00      0.00       1.0\n",
      "         940       0.00      0.00      0.00       1.0\n",
      "         941       0.00      0.00      0.00       1.0\n",
      "         942       0.00      0.00      0.00       1.0\n",
      "         943       0.00      0.00      0.00       1.0\n",
      "         944       0.00      0.00      0.00       1.0\n",
      "         945       0.00      0.00      0.00       1.0\n",
      "         946       0.00      0.00      0.00       1.0\n",
      "         947       0.00      0.00      0.00       1.0\n",
      "         948       0.00      0.00      0.00       1.0\n",
      "         949       0.00      0.00      0.00       1.0\n",
      "         950       0.00      0.00      0.00       1.0\n",
      "         951       0.00      0.00      0.00       1.0\n",
      "         952       0.00      0.00      0.00       1.0\n",
      "         954       0.00      0.00      0.00       1.0\n",
      "         955       0.00      0.00      0.00       1.0\n",
      "         956       0.00      0.00      0.00       1.0\n",
      "         957       0.00      0.00      0.00       1.0\n",
      "         958       0.00      0.00      0.00       1.0\n",
      "         959       0.00      0.00      0.00       1.0\n",
      "         960       0.00      0.00      0.00       1.0\n",
      "         961       0.00      0.00      0.00       1.0\n",
      "         962       0.00      0.00      0.00       1.0\n",
      "         963       0.00      0.00      0.00       1.0\n",
      "         964       0.00      0.00      0.00       1.0\n",
      "         965       0.00      0.00      0.00       1.0\n",
      "         966       0.00      0.00      0.00       1.0\n",
      "         967       0.00      0.00      0.00       1.0\n",
      "         968       0.00      0.00      0.00       1.0\n",
      "         970       0.00      0.00      0.00       1.0\n",
      "         971       0.00      0.00      0.00       1.0\n",
      "         972       0.00      0.00      0.00       1.0\n",
      "         973       0.00      0.00      0.00       1.0\n",
      "         974       0.00      0.00      0.00       1.0\n",
      "         975       0.00      0.00      0.00       1.0\n",
      "         976       0.00      0.00      0.00       1.0\n",
      "         977       0.00      0.00      0.00       1.0\n",
      "         978       0.00      0.00      0.00       1.0\n",
      "         979       0.00      0.00      0.00       1.0\n",
      "         980       0.00      0.00      0.00       1.0\n",
      "         981       0.00      0.00      0.00       1.0\n",
      "         982       0.00      0.00      0.00       1.0\n",
      "         983       0.00      0.00      0.00       1.0\n",
      "         984       0.00      0.00      0.00       1.0\n",
      "         985       0.00      0.00      0.00       1.0\n",
      "         986       0.00      0.00      0.00       1.0\n",
      "         987       0.00      0.00      0.00       1.0\n",
      "         988       0.00      0.00      0.00       1.0\n",
      "         989       0.00      0.00      0.00       1.0\n",
      "         990       0.00      0.00      0.00       1.0\n",
      "         991       0.00      0.00      0.00       1.0\n",
      "         992       0.00      0.00      0.00       1.0\n",
      "         993       0.00      0.00      0.00       1.0\n",
      "         994       0.00      0.00      0.00       1.0\n",
      "         995       0.00      0.00      0.00       1.0\n",
      "         996       0.00      0.00      0.00       1.0\n",
      "         997       0.00      0.00      0.00       1.0\n",
      "         998       0.00      0.00      0.00       1.0\n",
      "         999       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00      93.0\n",
      "   macro avg       0.00      0.00      0.00      93.0\n",
      "weighted avg       0.00      0.00      0.00      93.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunwanx/miniconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yunwanx/miniconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(test_data_y,test_data_y_pred_logistic))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
